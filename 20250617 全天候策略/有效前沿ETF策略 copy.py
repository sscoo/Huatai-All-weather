# https://mp.weixin.qq.com/s/f0YqHAT9Wn1qpKb8-4oj_w
# ä¿®æ”¹ç‰ˆæœ¬ï¼šæ”¯æŒæ¯æœˆæœˆåˆå’Œæœˆä¸­è°ƒä»“ï¼ˆæ¯æœˆä¸¤æ¬¡è°ƒä»“ï¼‰
# ä¸»è¦ä¿®æ”¹ï¼š
# 1. monthly_rebalancing_backtestå‡½æ•°ï¼šæ”¯æŒæ¯æœˆå¤šä¸ªè°ƒä»“æ—¥æœŸ
# 2. run_monthly_analysiså‡½æ•°ï¼šæ–°å¢rebalance_dayså‚æ•°
# 3. é»˜è®¤è°ƒä»“æ—¥æœŸè®¾ç½®ä¸º[1, 15]ï¼Œå³æ¯æœˆ1æ—¥å’Œ15æ—¥
import akshare as ak
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.optimize import minimize
import warnings
from datetime import datetime, timedelta
import matplotlib

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')

class EfficientFrontierETF:
    def __init__(self):
        # ETFä»£ç å’Œåç§°
        # self.etf_codes = {
        #     '159934': 'é»„é‡‘ETF',
        #     '515450': 'çº¢åˆ©ä½æ³¢50ETF', 
        #     '513100': 'çº³æŒ‡ETF',
        #     '161716': 'æ‹›å•†åŒå€ºLOF',
        #     '159985': 'è±†ç²•ETF',
        #     '513880': 'æ—¥ç»225ETF',
        #     '510300': 'æ²ªæ·±300ETF',
        #     '159920': 'æ’ç”ŸETF',
        #     '159740': 'æ’ç”Ÿç§‘æŠ€ETF',
        #     '511090': '30å¹´å›½å€ºETF',
        #     '159980': 'æœ‰è‰²ETF',
        #     '160723': 'å˜‰å®åŸæ²¹LOF'
        # }
        self.etf_codes = {
            '159934': 'é»„é‡‘ETF',
            '510880': 'çº¢åˆ©ETF', 
            '513630': 'æ¸¯è‚¡çº¢åˆ©æŒ‡æ•°ETF',
            '513100': 'çº³æŒ‡ETF',
            '588000': 'ç§‘åˆ›50ETF',
            '510500': 'ä¸­è¯500ETF',
            '513880': 'æ—¥ç»225ETF',
            '510300': 'æ²ªæ·±300ETF',
            '159920': 'æ’ç”ŸETF',
            '159740': 'æ’ç”Ÿç§‘æŠ€ETF',
            '511090': '30å¹´å›½å€ºETF',
            '159980': 'æœ‰è‰²ETF',
            '160723': 'å˜‰å®åŸæ²¹LOF'
        }

        
        self.data = None
        self.returns = None
        self.mean_returns = None
        self.cov_matrix = None
        
    def get_etf_data(self, start_date='20200101', end_date=None):
        """
        è·å–ETFå†å²æ•°æ®
        
        æ³¨æ„ï¼š
        - ä½¿ç”¨åå¤æƒä»·æ ¼(hfq)è®¡ç®—æ”¶ç›Šç‡ï¼Œè¿™æ ·èƒ½æ›´å‡†ç¡®åæ˜ çœŸå®æŠ•èµ„å›æŠ¥
        - åå¤æƒä»·æ ¼å·²è€ƒè™‘åˆ†çº¢ã€æ‹†åˆ†ç­‰å› ç´ å¯¹å†å²ä»·æ ¼çš„å½±å“
        - å¯¹äºæŠ•èµ„ç»„åˆä¼˜åŒ–å’Œé£é™©è¯„ä¼°ï¼Œä½¿ç”¨å¤æƒä»·æ ¼æ˜¯æ›´åˆç†çš„é€‰æ‹©
        """
        if end_date is None:
            end_date = datetime.now().strftime('%Y%m%d')
            
        print("æ­£åœ¨è·å–ETFæ•°æ®...")
        all_data = {}
        
        for code, name in self.etf_codes.items():
            try:
                print(f"è·å– {code} {name} æ•°æ®...")
                # è·å–ETFå†å²æ•°æ®ï¼ˆä½¿ç”¨åå¤æƒä»·æ ¼ï¼‰
                df = ak.fund_etf_hist_em(symbol=code, period="daily", start_date=start_date, end_date=end_date, adjust="hfq")
                if df is not None and len(df) > 0:
                    # åªä¿ç•™åå¤æƒæ”¶ç›˜ä»·
                    df = df[['æ—¥æœŸ', 'æ”¶ç›˜']].copy()
                    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
                    df.set_index('æ—¥æœŸ', inplace=True)
                    df.columns = [name]
                    all_data[name] = df
                    print(f"æˆåŠŸè·å– {name} æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
                else:
                    print(f"è·å– {name} æ•°æ®å¤±è´¥")
            except Exception as e:
                print(f"è·å– {code} {name} æ•°æ®æ—¶å‡ºé”™: {e}")
                
        if len(all_data) == 0:
            raise ValueError("æ²¡æœ‰æˆåŠŸè·å–ä»»ä½•ETFæ•°æ®")
            
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        self.data = pd.concat(all_data.values(), axis=1, join='inner')
        print(f"æ•°æ®åˆå¹¶å®Œæˆï¼Œå…± {len(self.data)} ä¸ªäº¤æ˜“æ—¥")
        
        return self.data
    
    def calculate_returns(self):
        """
        è®¡ç®—æ”¶ç›Šç‡
        """
        if self.data is None:
            raise ValueError("è¯·å…ˆè·å–æ•°æ®")
            
        # è®¡ç®—æ—¥æ”¶ç›Šç‡
        self.returns = self.data.pct_change().dropna()
        
        # è®¡ç®—å¹´åŒ–å‡å€¼æ”¶ç›Šç‡å’Œåæ–¹å·®çŸ©é˜µ
        self.mean_returns = self.returns.mean() * 252  # å¹´åŒ–
        self.cov_matrix = self.returns.cov() * 252     # å¹´åŒ–
        
        print("æ”¶ç›Šç‡è®¡ç®—å®Œæˆ")
        print(f"å¹´åŒ–æ”¶ç›Šç‡:\n{self.mean_returns}")
        
        return self.returns
    
    def portfolio_performance(self, weights):
        """
        è®¡ç®—æŠ•èµ„ç»„åˆè¡¨ç°
        """
        portfolio_return = np.sum(self.mean_returns * weights)
        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(self.cov_matrix, weights)))
        sharpe_ratio = portfolio_return / portfolio_volatility if portfolio_volatility > 0 else 0
        
        return portfolio_return, portfolio_volatility, sharpe_ratio
    
    def calculate_portfolio_returns(self, weights):
        """
        è®¡ç®—æŠ•èµ„ç»„åˆçš„å†å²æ”¶ç›Šç‡åºåˆ—
        """
        portfolio_returns = (self.returns * weights).sum(axis=1)
        return portfolio_returns
    
    def calculate_max_drawdown(self, weights):
        """
        è®¡ç®—æœ€å¤§å›æ’¤
        """
        portfolio_returns = self.calculate_portfolio_returns(weights)
        cumulative_returns = (1 + portfolio_returns).cumprod()
        
        # è®¡ç®—æœ€å¤§å›æ’¤
        peak = cumulative_returns.expanding().max()
        drawdown = (cumulative_returns - peak) / peak
        max_drawdown = drawdown.min()
        
        return abs(max_drawdown)
    
    def calculate_calmar_ratio(self, weights):
        """
        è®¡ç®—å¡ç›æ¯”ç‡ (å¹´åŒ–æ”¶ç›Šç‡ / æœ€å¤§å›æ’¤)
        """
        portfolio_return, _, _ = self.portfolio_performance(weights)
        max_drawdown = self.calculate_max_drawdown(weights)
        
        calmar_ratio = portfolio_return / max_drawdown if max_drawdown > 0 else 0
        return calmar_ratio
    
    def negative_sharpe_ratio(self, weights):
        """
        è´Ÿå¤æ™®æ¯”ç‡ (ç”¨äºæœ€å°åŒ–)
        """
        _, _, sharpe = self.portfolio_performance(weights)
        return -sharpe
    
    def negative_calmar_ratio(self, weights):
        """
        è´Ÿå¡ç›æ¯”ç‡ (ç”¨äºæœ€å°åŒ–)
        """
        calmar = self.calculate_calmar_ratio(weights)
        return -calmar
    
    def portfolio_volatility(self, weights):
        """
        æŠ•èµ„ç»„åˆæ³¢åŠ¨ç‡
        """
        _, volatility, _ = self.portfolio_performance(weights)
        return volatility
    
    def generate_efficient_frontier(self, num_portfolios=10000):
        """
        ç”Ÿæˆæœ‰æ•ˆå‰æ²¿
        """
        if self.returns is None:
            raise ValueError("è¯·å…ˆè®¡ç®—æ”¶ç›Šç‡")
            
        num_assets = len(self.etf_codes)
        
        # çº¦æŸæ¡ä»¶ï¼šæƒé‡å’Œä¸º1ï¼Œæ¯ä¸ªæƒé‡åœ¨0-1ä¹‹é—´
        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
        bounds = tuple((0, 1) for _ in range(num_assets))
        
        # å­˜å‚¨ç»“æœ
        results = np.zeros((4, num_portfolios))  # returns, volatility, sharpe, weights
        
        print("æ­£åœ¨ç”Ÿæˆæœ‰æ•ˆå‰æ²¿...")
        
        # éšæœºç”ŸæˆæŠ•èµ„ç»„åˆ
        for i in range(num_portfolios):
            # ç”Ÿæˆéšæœºæƒé‡å¹¶æ ‡å‡†åŒ–
            weights = np.random.random(num_assets)
            weights /= np.sum(weights)
            
            # è®¡ç®—æŠ•èµ„ç»„åˆè¡¨ç°
            portfolio_return, portfolio_vol, sharpe = self.portfolio_performance(weights)
            
            results[0, i] = portfolio_return
            results[1, i] = portfolio_vol
            results[2, i] = sharpe
            
        self.efficient_frontier_data = results
        print("æœ‰æ•ˆå‰æ²¿ç”Ÿæˆå®Œæˆ")
        
        return results
    
    def find_optimal_portfolios(self):
        """
        æ‰¾åˆ°ä¸‰ä¸ªæœ€ä¼˜æŠ•èµ„ç»„åˆ
        """
        num_assets = len(self.etf_codes)
        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
        bounds = tuple((0, 1) for _ in range(num_assets))
        
        # åˆå§‹çŒœæµ‹ - ç­‰æƒé‡
        initial_guess = np.array([1/num_assets] * num_assets)
        
        # 1. æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ
        print("å¯»æ‰¾æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ...")
        max_sharpe_result = minimize(
            self.negative_sharpe_ratio, 
            initial_guess, 
            method='SLSQP', 
            bounds=bounds, 
            constraints=constraints
        )
        max_sharpe_weights = max_sharpe_result.x
        
        # 2. æœ€å¤§å¡ç›æ¯”ç‡ç»„åˆ
        print("å¯»æ‰¾æœ€å¤§å¡ç›æ¯”ç‡ç»„åˆ...")
        max_calmar_result = minimize(
            self.negative_calmar_ratio, 
            initial_guess, 
            method='SLSQP', 
            bounds=bounds, 
            constraints=constraints
        )
        max_calmar_weights = max_calmar_result.x
        
        # 3. æ§åˆ¶å›æ’¤çš„é«˜æ”¶ç›Šç»„åˆ
        print("å¯»æ‰¾æ§åˆ¶å›æ’¤çš„é«˜æ”¶ç›Šç»„åˆ...")
        # æ·»åŠ æœ€å¤§å›æ’¤çº¦æŸ
        def max_drawdown_constraint(weights):
            return 0.10 - self.calculate_max_drawdown(weights)  # æœ€å¤§å›æ’¤ä¸è¶…è¿‡10%
        
        drawdown_constraints = [
            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
            {'type': 'ineq', 'fun': max_drawdown_constraint}
        ]
        
        # æœ€å¤§åŒ–æ”¶ç›Šç‡ï¼ˆæœ€å°åŒ–è´Ÿæ”¶ç›Šç‡ï¼‰
        def negative_return(weights):
            ret, _, _ = self.portfolio_performance(weights)
            return -ret
        
        high_return_result = minimize(
            negative_return, 
            initial_guess, 
            method='SLSQP', 
            bounds=bounds, 
            constraints=drawdown_constraints
        )
        high_return_weights = high_return_result.x
        
        # å¦‚æœä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ
        if not high_return_result.success:
            print("é«˜æ”¶ç›Šç»„åˆä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ...")
            # å°è¯•ä¸åŒçš„åˆå§‹å€¼
            for _ in range(10):
                random_initial = np.random.random(num_assets)
                random_initial /= np.sum(random_initial)
                
                result = minimize(
                    negative_return, 
                    random_initial, 
                    method='SLSQP', 
                    bounds=bounds, 
                    constraints=drawdown_constraints
                )
                
                if result.success:
                    high_return_weights = result.x
                    break
            else:
                # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œä½¿ç”¨é£é™©å¹³ä»·æƒé‡
                high_return_weights = np.array([0.3, 0.25, 0.2, 0.15, 0.1])
        
        self.optimal_portfolios = {
            'max_sharpe': max_sharpe_weights,
            'max_calmar': max_calmar_weights,
            'high_return': high_return_weights
        }
        
        return self.optimal_portfolios
    
    def analyze_portfolios(self):
        """
        åˆ†æä¸‰ä¸ªæœ€ä¼˜æŠ•èµ„ç»„åˆ
        """
        if not hasattr(self, 'optimal_portfolios'):
            raise ValueError("è¯·å…ˆæ‰¾åˆ°æœ€ä¼˜æŠ•èµ„ç»„åˆ")
            
        portfolio_names = ['æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ', 'æœ€å¤§å¡ç›æ¯”ç‡ç»„åˆ', 'æ§åˆ¶å›æ’¤é«˜æ”¶ç›Šç»„åˆ']
        portfolio_keys = ['max_sharpe', 'max_calmar', 'high_return']
        
        analysis_results = {}
        
        print("\n" + "="*80)
        print("æŠ•èµ„ç»„åˆåˆ†æç»“æœ")
        print("="*80)
        
        for i, (name, key) in enumerate(zip(portfolio_names, portfolio_keys)):
            weights = self.optimal_portfolios[key]
            
            # è®¡ç®—å„é¡¹æŒ‡æ ‡
            portfolio_return, portfolio_vol, sharpe = self.portfolio_performance(weights)
            max_drawdown = self.calculate_max_drawdown(weights)
            calmar_ratio = self.calculate_calmar_ratio(weights)
            
            analysis_results[key] = {
                'name': name,
                'weights': weights,
                'annual_return': portfolio_return,
                'volatility': portfolio_vol,
                'sharpe_ratio': sharpe,
                'max_drawdown': max_drawdown,
                'calmar_ratio': calmar_ratio
            }
            
            print(f"\nğŸ“Œ {name}")
            print("-" * 50)
            print(f"å¹´åŒ–æ”¶ç›Šç‡: {portfolio_return:.2%}")
            print(f"å¹´åŒ–æ³¢åŠ¨ç‡: {portfolio_vol:.2%}")
            print(f"å¤æ™®æ¯”ç‡: {sharpe:.3f}")
            print(f"æœ€å¤§å›æ’¤: {max_drawdown:.2%}")
            print(f"å¡ç›æ¯”ç‡: {calmar_ratio:.3f}")
            print("\nèµ„äº§é…ç½®:")
            
            for j, (code, etf_name) in enumerate(self.etf_codes.items()):
                print(f"  {etf_name}: {weights[j]:.1%}")
        
        self.analysis_results = analysis_results
        return analysis_results
    
    def plot_efficient_frontier(self, save_path=None):
        """
        ç»˜åˆ¶æœ‰æ•ˆå‰æ²¿å›¾
        """
        if not hasattr(self, 'efficient_frontier_data'):
            raise ValueError("è¯·å…ˆç”Ÿæˆæœ‰æ•ˆå‰æ²¿")
            
        plt.figure(figsize=(14, 10))
        
        # åˆ›å»ºå­å›¾
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # å­å›¾1: æœ‰æ•ˆå‰æ²¿æ•£ç‚¹å›¾
        returns = self.efficient_frontier_data[0]
        volatilities = self.efficient_frontier_data[1]
        sharpe_ratios = self.efficient_frontier_data[2]
        
        scatter = ax1.scatter(volatilities, returns, c=sharpe_ratios, 
                            cmap='viridis', alpha=0.6, s=10)
        ax1.set_xlabel('å¹´åŒ–æ³¢åŠ¨ç‡')
        ax1.set_ylabel('å¹´åŒ–æ”¶ç›Šç‡')
        ax1.set_title('æœ‰æ•ˆå‰æ²¿')
        plt.colorbar(scatter, ax=ax1, label='å¤æ™®æ¯”ç‡')
        
        # æ ‡è®°ä¸‰ä¸ªæœ€ä¼˜ç»„åˆ
        if hasattr(self, 'optimal_portfolios'):
            colors = ['red', 'blue', 'green']
            labels = ['æœ€å¤§å¤æ™®æ¯”ç‡', 'æœ€å¤§å¡ç›æ¯”ç‡', 'æ§åˆ¶å›æ’¤é«˜æ”¶ç›Š']
            
            for i, (key, color, label) in enumerate(zip(['max_sharpe', 'max_calmar', 'high_return'], 
                                                       colors, labels)):
                weights = self.optimal_portfolios[key]
                ret, vol, _ = self.portfolio_performance(weights)
                ax1.scatter(vol, ret, color=color, s=100, marker='*', 
                           label=label, edgecolors='white', linewidth=2)
        
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # å­å›¾2: æƒé‡åˆ†å¸ƒå¯¹æ¯”
        if hasattr(self, 'analysis_results'):
            portfolio_names = ['æœ€å¤§å¤æ™®æ¯”ç‡', 'æœ€å¤§å¡ç›æ¯”ç‡', 'æ§åˆ¶å›æ’¤é«˜æ”¶ç›Š']
            portfolio_keys = ['max_sharpe', 'max_calmar', 'high_return']
            
            # å‡†å¤‡æ•°æ®
            weights_data = []
            for key in portfolio_keys:
                weights_data.append(self.analysis_results[key]['weights'])
            
            weights_df = pd.DataFrame(weights_data, 
                                    columns=list(self.etf_codes.values()),
                                    index=portfolio_names)
            
            # ç»˜åˆ¶å †å æŸ±çŠ¶å›¾
            weights_df.plot(kind='bar', stacked=True, ax=ax2, 
                           colormap='Set3', width=0.8)
            ax2.set_title('æŠ•èµ„ç»„åˆæƒé‡åˆ†å¸ƒ')
            ax2.set_ylabel('æƒé‡')
            ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax2.set_xticklabels(portfolio_names, rotation=45)
            
        # å­å›¾3: é£é™©æ”¶ç›Šæ•£ç‚¹å›¾
        if hasattr(self, 'analysis_results'):
            returns_list = []
            volatilities_list = []
            names_list = []
            
            for key in portfolio_keys:
                result = self.analysis_results[key]
                returns_list.append(result['annual_return'])
                volatilities_list.append(result['volatility'])
                names_list.append(result['name'])
            
            ax3.scatter(volatilities_list, returns_list, 
                       c=['red', 'blue', 'green'], s=200, alpha=0.7)
            
            for i, name in enumerate(names_list):
                ax3.annotate(name, (volatilities_list[i], returns_list[i]),
                           xytext=(5, 5), textcoords='offset points', fontsize=9)
            
            ax3.set_xlabel('å¹´åŒ–æ³¢åŠ¨ç‡')
            ax3.set_ylabel('å¹´åŒ–æ”¶ç›Šç‡')
            ax3.set_title('æœ€ä¼˜æŠ•èµ„ç»„åˆå¯¹æ¯”')
            ax3.grid(True, alpha=0.3)
        
        # å­å›¾4: å…³é”®æŒ‡æ ‡å¯¹æ¯”
        if hasattr(self, 'analysis_results'):
            metrics = ['å¤æ™®æ¯”ç‡', 'å¡ç›æ¯”ç‡', 'æœ€å¤§å›æ’¤']
            portfolio_metrics = {name: [] for name in portfolio_names}
            
            for key, name in zip(portfolio_keys, portfolio_names):
                result = self.analysis_results[key]
                portfolio_metrics[name].append(result['sharpe_ratio'])
                portfolio_metrics[name].append(result['calmar_ratio'])
                portfolio_metrics[name].append(result['max_drawdown'])
            
            x = np.arange(len(metrics))
            width = 0.25
            
            for i, (name, values) in enumerate(portfolio_metrics.items()):
                ax4.bar(x + i*width, values, width, label=name, alpha=0.8)
            
            ax4.set_xlabel('æŒ‡æ ‡')
            ax4.set_ylabel('æ•°å€¼')
            ax4.set_title('å…³é”®æŒ‡æ ‡å¯¹æ¯”')
            ax4.set_xticks(x + width)
            ax4.set_xticklabels(metrics)
            ax4.legend()
            ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def run_complete_analysis(self, start_date='20200101', save_results=True):
        """
        è¿è¡Œå®Œæ•´åˆ†ææµç¨‹
        """
        print("å¼€å§‹æœ‰æ•ˆå‰æ²¿ETFç­–ç•¥åˆ†æ...")
        print("="*80)
        
        # 1. è·å–æ•°æ®
        self.get_etf_data(start_date=start_date)
        
        # 2. è®¡ç®—æ”¶ç›Šç‡
        self.calculate_returns()
        
        # 3. ç”Ÿæˆæœ‰æ•ˆå‰æ²¿
        self.generate_efficient_frontier()
        
        # 4. æ‰¾åˆ°æœ€ä¼˜æŠ•èµ„ç»„åˆ
        self.find_optimal_portfolios()
        
        # 5. åˆ†æç»“æœ
        self.analyze_portfolios()
        
        # 6. ç»˜åˆ¶å›¾è¡¨
        if save_results:
            save_path = 'efficient_frontier_analysis.png'
            self.plot_efficient_frontier(save_path=save_path)
        else:
            self.plot_efficient_frontier()
        
        print("\n" + "="*80)
        print("åˆ†æå®Œæˆï¼")
        print("="*80)
        
        return self.analysis_results
    
    def split_sample_data(self, in_sample_start='20200101', in_sample_end='20231231', 
                         out_sample_start='20240101', out_sample_end=None):
        """
        åˆ†å‰²æ ·æœ¬å†…å¤–æ•°æ®
        
        Parameters:
        - in_sample_start: æ ·æœ¬å†…å¼€å§‹æ—¥æœŸ
        - in_sample_end: æ ·æœ¬å†…ç»“æŸæ—¥æœŸ
        - out_sample_start: æ ·æœ¬å¤–å¼€å§‹æ—¥æœŸ
        - out_sample_end: æ ·æœ¬å¤–ç»“æŸæ—¥æœŸ
        """
        if out_sample_end is None:
            out_sample_end = datetime.now().strftime('%Y%m%d')
        
        print("åˆ†å‰²æ ·æœ¬å†…å¤–æ•°æ®...")
        
        # è·å–å®Œæ•´æ•°æ®
        full_start = min(in_sample_start, out_sample_start)
        self.get_etf_data(start_date=full_start, end_date=out_sample_end)
        
        # åˆ†å‰²æ•°æ®
        in_sample_start_dt = pd.to_datetime(in_sample_start)
        in_sample_end_dt = pd.to_datetime(in_sample_end)
        out_sample_start_dt = pd.to_datetime(out_sample_start)
        out_sample_end_dt = pd.to_datetime(out_sample_end)
        
        # æ ·æœ¬å†…æ•°æ®
        self.in_sample_data = self.data[
            (self.data.index >= in_sample_start_dt) & 
            (self.data.index <= in_sample_end_dt)
        ].copy()
        
        # æ ·æœ¬å¤–æ•°æ®
        self.out_sample_data = self.data[
            (self.data.index >= out_sample_start_dt) & 
            (self.data.index <= out_sample_end_dt)
        ].copy()
        
        print(f"æ ·æœ¬å†…æ•°æ®: {len(self.in_sample_data)} ä¸ªäº¤æ˜“æ—¥ ({in_sample_start} - {in_sample_end})")
        print(f"æ ·æœ¬å¤–æ•°æ®: {len(self.out_sample_data)} ä¸ªäº¤æ˜“æ—¥ ({out_sample_start} - {out_sample_end})")
        
        return self.in_sample_data, self.out_sample_data
    
    def train_on_in_sample(self):
        """
        åœ¨æ ·æœ¬å†…æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œé€‰æ‹©æœ€ä¼˜æŠ•èµ„ç»„åˆ
        """
        print("\n" + "="*60)
        print("æ ·æœ¬å†…åˆ†æ (2020-2023)")
        print("="*60)
        
        # ä½¿ç”¨æ ·æœ¬å†…æ•°æ®è®¡ç®—æ”¶ç›Šç‡
        original_data = self.data
        self.data = self.in_sample_data
        
        # è®¡ç®—æ”¶ç›Šç‡
        self.calculate_returns()
        
        # ç”Ÿæˆæœ‰æ•ˆå‰æ²¿
        self.generate_efficient_frontier()
        
        # æ‰¾åˆ°æœ€ä¼˜æŠ•èµ„ç»„åˆ
        self.find_optimal_portfolios()
        
        # åˆ†æç»“æœ
        in_sample_results = self.analyze_portfolios()
        
        # ä¿å­˜æ ·æœ¬å†…æœ€ä¼˜æƒé‡
        self.in_sample_optimal_portfolios = self.optimal_portfolios.copy()
        
        # æ¢å¤åŸå§‹æ•°æ®
        self.data = original_data
        
        return in_sample_results
    
    def backtest_portfolio(self, weights, data, portfolio_name="æŠ•èµ„ç»„åˆ"):
        """
        å›æµ‹å•ä¸ªæŠ•èµ„ç»„åˆ
        """
        # è®¡ç®—æ”¶ç›Šç‡
        returns = data.pct_change().dropna()
        
        # è®¡ç®—æŠ•èµ„ç»„åˆæ”¶ç›Šç‡åºåˆ—
        portfolio_returns = (returns * weights).sum(axis=1)
        
        # è®¡ç®—ç´¯è®¡æ”¶ç›Šç‡
        cumulative_returns = (1 + portfolio_returns).cumprod()
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        annual_return = portfolio_returns.mean() * 252
        annual_volatility = portfolio_returns.std() * np.sqrt(252)
        sharpe_ratio = annual_return / annual_volatility if annual_volatility > 0 else 0
        
        # è®¡ç®—æœ€å¤§å›æ’¤
        peak = cumulative_returns.expanding().max()
        drawdown = (cumulative_returns - peak) / peak
        max_drawdown = abs(drawdown.min())
        
        # è®¡ç®—å¡ç›æ¯”ç‡
        calmar_ratio = annual_return / max_drawdown if max_drawdown > 0 else 0
        
        # è®¡ç®—å…¶ä»–æŒ‡æ ‡
        total_return = cumulative_returns.iloc[-1] - 1
        win_rate = (portfolio_returns > 0).mean()
        
        backtest_result = {
            'portfolio_name': portfolio_name,
            'weights': weights,
            'portfolio_returns': portfolio_returns,
            'cumulative_returns': cumulative_returns,
            'total_return': total_return,
            'annual_return': annual_return,
            'annual_volatility': annual_volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'calmar_ratio': calmar_ratio,
            'win_rate': win_rate
        }
        
        return backtest_result
    
    def out_sample_backtest(self):
        """
        æ ·æœ¬å¤–å›æµ‹
        """
        print("\n" + "="*60)
        print("æ ·æœ¬å¤–å›æµ‹ (2024è‡³ä»Š)")
        print("="*60)
        
        if not hasattr(self, 'in_sample_optimal_portfolios'):
            raise ValueError("è¯·å…ˆè¿›è¡Œæ ·æœ¬å†…åˆ†æ")
        
        portfolio_names = ['æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ', 'æœ€å¤§å¡ç›æ¯”ç‡ç»„åˆ', 'æ§åˆ¶å›æ’¤é«˜æ”¶ç›Šç»„åˆ']
        portfolio_keys = ['max_sharpe', 'max_calmar', 'high_return']
        
        self.out_sample_results = {}
        
        for name, key in zip(portfolio_names, portfolio_keys):
            weights = self.in_sample_optimal_portfolios[key]
            
            # æ ·æœ¬å¤–å›æµ‹
            backtest_result = self.backtest_portfolio(
                weights, self.out_sample_data, name
            )
            
            self.out_sample_results[key] = backtest_result
            
            print(f"\nğŸ“Œ {name} - æ ·æœ¬å¤–è¡¨ç°")
            print("-" * 45)
            print(f"æ€»æ”¶ç›Šç‡: {backtest_result['total_return']:.2%}")
            print(f"å¹´åŒ–æ”¶ç›Šç‡: {backtest_result['annual_return']:.2%}")
            print(f"å¹´åŒ–æ³¢åŠ¨ç‡: {backtest_result['annual_volatility']:.2%}")
            print(f"å¤æ™®æ¯”ç‡: {backtest_result['sharpe_ratio']:.3f}")
            print(f"æœ€å¤§å›æ’¤: {backtest_result['max_drawdown']:.2%}")
            print(f"å¡ç›æ¯”ç‡: {backtest_result['calmar_ratio']:.3f}")
            print(f"èƒœç‡: {backtest_result['win_rate']:.1%}")
        
        return self.out_sample_results
    
    def compare_in_out_sample(self):
        """
        å¯¹æ¯”æ ·æœ¬å†…å¤–è¡¨ç°
        """
        print("\n" + "="*80)
        print("æ ·æœ¬å†…å¤–è¡¨ç°å¯¹æ¯”")
        print("="*80)
        
        portfolio_names = ['æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ', 'æœ€å¤§å¡ç›æ¯”ç‡ç»„åˆ', 'æ§åˆ¶å›æ’¤é«˜æ”¶ç›Šç»„åˆ']
        portfolio_keys = ['max_sharpe', 'max_calmar', 'high_return']
        
        comparison_data = []
        
        for name, key in zip(portfolio_names, portfolio_keys):
            # æ ·æœ¬å†…è¡¨ç°
            in_sample = self.analysis_results[key]
            
            # æ ·æœ¬å¤–è¡¨ç°
            out_sample = self.out_sample_results[key]
            
            comparison_data.append({
                'æŠ•èµ„ç»„åˆ': name,
                'æ ·æœ¬å†…å¹´åŒ–æ”¶ç›Šç‡': f"{in_sample['annual_return']:.2%}",
                'æ ·æœ¬å¤–å¹´åŒ–æ”¶ç›Šç‡': f"{out_sample['annual_return']:.2%}",
                'æ ·æœ¬å†…å¤æ™®æ¯”ç‡': f"{in_sample['sharpe_ratio']:.3f}",
                'æ ·æœ¬å¤–å¤æ™®æ¯”ç‡': f"{out_sample['sharpe_ratio']:.3f}",
                'æ ·æœ¬å†…æœ€å¤§å›æ’¤': f"{in_sample['max_drawdown']:.2%}",
                'æ ·æœ¬å¤–æœ€å¤§å›æ’¤': f"{out_sample['max_drawdown']:.2%}",
                'æ ·æœ¬å†…å¡ç›æ¯”ç‡': f"{in_sample['calmar_ratio']:.3f}",
                'æ ·æœ¬å¤–å¡ç›æ¯”ç‡': f"{out_sample['calmar_ratio']:.3f}"
            })
        
        # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
        comparison_df = pd.DataFrame(comparison_data)
        print(comparison_df.to_string(index=False))
        
        return comparison_df
    
    def plot_backtest_results(self, save_path=None):
        """
        ç»˜åˆ¶å›æµ‹ç»“æœå›¾è¡¨
        """
        if not hasattr(self, 'out_sample_results'):
            raise ValueError("è¯·å…ˆè¿›è¡Œæ ·æœ¬å¤–å›æµ‹")
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        portfolio_names = ['æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ', 'æœ€å¤§å¡ç›æ¯”ç‡ç»„åˆ', 'æ§åˆ¶å›æ’¤é«˜æ”¶ç›Šç»„åˆ']
        portfolio_keys = ['max_sharpe', 'max_calmar', 'high_return']
        colors = ['red', 'blue', 'green']
        
        # å­å›¾1: æ ·æœ¬å¤–ç´¯è®¡æ”¶ç›Šç‡æ›²çº¿
        ax1 = axes[0, 0]
        for key, name, color in zip(portfolio_keys, portfolio_names, colors):
            cum_returns = self.out_sample_results[key]['cumulative_returns']
            ax1.plot(cum_returns.index, cum_returns, label=name, color=color, linewidth=2)
        
        ax1.set_title('æ ·æœ¬å¤–ç´¯è®¡æ”¶ç›Šç‡æ›²çº¿')
        ax1.set_ylabel('ç´¯è®¡æ”¶ç›Šç‡')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # å­å›¾2: æ ·æœ¬å†…å¤–å¹´åŒ–æ”¶ç›Šç‡å¯¹æ¯”
        ax2 = axes[0, 1]
        in_sample_returns = [self.analysis_results[key]['annual_return'] for key in portfolio_keys]
        out_sample_returns = [self.out_sample_results[key]['annual_return'] for key in portfolio_keys]
        
        x = np.arange(len(portfolio_names))
        width = 0.35
        
        ax2.bar(x - width/2, in_sample_returns, width, label='æ ·æœ¬å†…', alpha=0.8)
        ax2.bar(x + width/2, out_sample_returns, width, label='æ ·æœ¬å¤–', alpha=0.8)
        
        ax2.set_ylabel('å¹´åŒ–æ”¶ç›Šç‡')
        ax2.set_title('æ ·æœ¬å†…å¤–å¹´åŒ–æ”¶ç›Šç‡å¯¹æ¯”')
        ax2.set_xticks(x)
        ax2.set_xticklabels([name.replace('ç»„åˆ', '') for name in portfolio_names], rotation=45)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # å­å›¾3: æ ·æœ¬å†…å¤–å¤æ™®æ¯”ç‡å¯¹æ¯”
        ax3 = axes[1, 0]
        in_sample_sharpe = [self.analysis_results[key]['sharpe_ratio'] for key in portfolio_keys]
        out_sample_sharpe = [self.out_sample_results[key]['sharpe_ratio'] for key in portfolio_keys]
        
        ax3.bar(x - width/2, in_sample_sharpe, width, label='æ ·æœ¬å†…', alpha=0.8)
        ax3.bar(x + width/2, out_sample_sharpe, width, label='æ ·æœ¬å¤–', alpha=0.8)
        
        ax3.set_ylabel('å¤æ™®æ¯”ç‡')
        ax3.set_title('æ ·æœ¬å†…å¤–å¤æ™®æ¯”ç‡å¯¹æ¯”')
        ax3.set_xticks(x)
        ax3.set_xticklabels([name.replace('ç»„åˆ', '') for name in portfolio_names], rotation=45)
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # å­å›¾4: æ ·æœ¬å†…å¤–æœ€å¤§å›æ’¤å¯¹æ¯”
        ax4 = axes[1, 1]
        in_sample_drawdown = [self.analysis_results[key]['max_drawdown'] for key in portfolio_keys]
        out_sample_drawdown = [self.out_sample_results[key]['max_drawdown'] for key in portfolio_keys]
        
        ax4.bar(x - width/2, in_sample_drawdown, width, label='æ ·æœ¬å†…', alpha=0.8)
        ax4.bar(x + width/2, out_sample_drawdown, width, label='æ ·æœ¬å¤–', alpha=0.8)
        
        ax4.set_ylabel('æœ€å¤§å›æ’¤')
        ax4.set_title('æ ·æœ¬å†…å¤–æœ€å¤§å›æ’¤å¯¹æ¯”')
        ax4.set_xticks(x)
        ax4.set_xticklabels([name.replace('ç»„åˆ', '') for name in portfolio_names], rotation=45)
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"å›æµ‹å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def run_in_out_sample_analysis(self, in_sample_start='20210101', in_sample_end='20230630',
                                  out_sample_start='20240101', out_sample_end=None, save_results=True):
        """
        è¿è¡Œå®Œæ•´çš„æ ·æœ¬å†…å¤–åˆ†æ
        """
        print("å¼€å§‹æ ·æœ¬å†…å¤–å›æµ‹åˆ†æ...")
        print("="*80)
        
        # 1. åˆ†å‰²æ•°æ®
        self.split_sample_data(in_sample_start, in_sample_end, out_sample_start, out_sample_end)
        
        # 2. æ ·æœ¬å†…åˆ†æ
        in_sample_results = self.train_on_in_sample()
        
        # 3. æ ·æœ¬å¤–å›æµ‹
        out_sample_results = self.out_sample_backtest()
        
        # 4. å¯¹æ¯”åˆ†æ
        comparison_df = self.compare_in_out_sample()
        
        # 5. ç»˜åˆ¶å›¾è¡¨
        if save_results:
            save_path = 'in_out_sample_backtest.png'
            self.plot_backtest_results(save_path=save_path)
        else:
            self.plot_backtest_results()
        
        print("\n" + "="*80)
        print("æ ·æœ¬å†…å¤–åˆ†æå®Œæˆï¼")
        print("="*80)
        
        return {
            'in_sample_results': in_sample_results,
            'out_sample_results': out_sample_results,
            'comparison': comparison_df
        }
    
    def monthly_rebalancing_backtest(self, start_date='20210101', end_date=None, 
                                   lookback_months=12, rebalance_days=[1, 15]):
        """
        æœˆåº¦è°ƒä»“å›æµ‹ - æ”¯æŒæ¯æœˆå¤šæ¬¡è°ƒä»“
        
        Parameters:
        - start_date: å›æµ‹å¼€å§‹æ—¥æœŸ
        - end_date: å›æµ‹ç»“æŸæ—¥æœŸ
        - lookback_months: ä¼˜åŒ–æ—¶ä½¿ç”¨çš„å†å²æ•°æ®é•¿åº¦(æœˆ)
        - rebalance_days: æ¯æœˆè°ƒä»“æ—¥æœŸåˆ—è¡¨ï¼Œé»˜è®¤[1, 15]è¡¨ç¤ºæ¯æœˆ1æ—¥å’Œ15æ—¥è°ƒä»“
        """
        if end_date is None:
            end_date = datetime.now().strftime('%Y%m%d')
        
        print("\n" + "="*80)
        print("æœˆåº¦åŠ¨æ€è°ƒä»“å›æµ‹åˆ†æ")
        print("="*80)
        print(f"å›æµ‹æœŸé—´: {start_date} - {end_date}")
        print(f"å†å²æ•°æ®çª—å£: {lookback_months} ä¸ªæœˆ")
        print(f"è°ƒä»“é¢‘ç‡: æ¯æœˆ {rebalance_days} æ—¥")
        
        # è·å–å®Œæ•´æ•°æ®
        full_start_date = pd.to_datetime(start_date) - pd.DateOffset(months=lookback_months + 2)
        self.get_etf_data(start_date=full_start_date.strftime('%Y%m%d'), end_date=end_date)
        
        # ç”Ÿæˆè°ƒä»“æ—¥æœŸ
        start_dt = pd.to_datetime(start_date)
        end_dt = pd.to_datetime(end_date)
        
        rebalance_dates = []
        
        # ç¡®å®šå¼€å§‹å¹´æœˆ
        current_year = start_dt.year
        current_month = start_dt.month
        
        while True:
            # ä¸ºå½“å‰æœˆä»½ç”Ÿæˆæ‰€æœ‰è°ƒä»“æ—¥æœŸ
            for rebalance_day in rebalance_days:
                try:
                    current_date = pd.Timestamp(year=current_year, month=current_month, day=rebalance_day)
                except ValueError:  # å¤„ç†æŸäº›æœˆä»½æ²¡æœ‰å¯¹åº”æ—¥æœŸçš„æƒ…å†µï¼ˆå¦‚2æœˆ30æ—¥ï¼‰
                    # å¦‚æœæŒ‡å®šæ—¥æœŸä¸å­˜åœ¨ï¼Œä½¿ç”¨å½“æœˆæœ€åä¸€å¤©
                    import calendar
                    last_day = calendar.monthrange(current_year, current_month)[1]
                    current_date = pd.Timestamp(year=current_year, month=current_month, 
                                              day=min(rebalance_day, last_day))
                
                # åªè€ƒè™‘åœ¨å›æµ‹æœŸé—´å†…çš„æ—¥æœŸ
                if current_date >= start_dt and current_date <= end_dt:
                    # æ‰¾åˆ°æœ€è¿‘çš„äº¤æ˜“æ—¥
                    search_date = current_date
                    found_trading_day = False
                    
                    # å‘å‰å‘åå„æœç´¢5ä¸ªå·¥ä½œæ—¥
                    for offset in range(-5, 6):
                        candidate_date = search_date + pd.Timedelta(days=offset)
                        if candidate_date in self.data.index and candidate_date <= end_dt:
                            rebalance_dates.append(candidate_date)
                            found_trading_day = True
                            break
                    
                    if not found_trading_day:
                        print(f"è­¦å‘Š: æœªæ‰¾åˆ° {current_date.strftime('%Y-%m-%d')} é™„è¿‘çš„äº¤æ˜“æ—¥")
            
            # ç§»åŠ¨åˆ°ä¸‹ä¸ªæœˆ
            if current_month == 12:
                current_year += 1
                current_month = 1
            else:
                current_month += 1
            
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºç»“æŸæ—¥æœŸ
            if pd.Timestamp(year=current_year, month=current_month, day=1) > end_dt:
                break
        
        # ç§»é™¤é‡å¤æ—¥æœŸå¹¶æ’åº
        rebalance_dates = sorted(list(set(rebalance_dates)))
        
        print(f"è°ƒä»“æ¬¡æ•°: {len(rebalance_dates)} æ¬¡ (æ¯æœˆ{len(rebalance_days)}æ¬¡)")
        
        # å­˜å‚¨æ¯æ¬¡è°ƒä»“çš„æƒé‡å’Œè¡¨ç°
        self.monthly_weights_history = {
            'dates': [],
            'max_sharpe_weights': [],
            'max_calmar_weights': [], 
            'high_return_weights': []
        }
        
        self.monthly_portfolio_returns = {
            'max_sharpe': [],
            'max_calmar': [],
            'high_return': []
        }
        
        # é€æœˆè¿›è¡Œä¼˜åŒ–å’Œå›æµ‹
        for i, rebalance_date in enumerate(rebalance_dates):
            print(f"\nç¬¬ {i+1} æ¬¡è°ƒä»“: {rebalance_date.strftime('%Y-%m-%d')}")
            
            # ç¡®å®šè®­ç»ƒæ•°æ®çª—å£
            train_start = rebalance_date - pd.DateOffset(months=lookback_months)
            train_end = rebalance_date - pd.Timedelta(days=1)
            
            # è·å–è®­ç»ƒæ•°æ®
            train_data = self.data[
                (self.data.index >= train_start) & 
                (self.data.index <= train_end)
            ].copy()
            
            if len(train_data) < 60:  # è‡³å°‘éœ€è¦60ä¸ªäº¤æ˜“æ—¥
                print(f"è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè·³è¿‡æœ¬æ¬¡è°ƒä»“")
                continue
            
            # åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿›è¡Œä¼˜åŒ–
            original_data = self.data
            self.data = train_data
            
            try:
                # è®¡ç®—æ”¶ç›Šç‡å’Œä¼˜åŒ–
                self.calculate_returns()
                self.find_optimal_portfolios()
                
                # åªæœ‰æˆåŠŸä¼˜åŒ–æ—¶æ‰ä¿å­˜æƒé‡å’Œæ—¥æœŸ
                self.monthly_weights_history['dates'].append(rebalance_date)
                self.monthly_weights_history['max_sharpe_weights'].append(
                    self.optimal_portfolios['max_sharpe'].copy()
                )
                self.monthly_weights_history['max_calmar_weights'].append(
                    self.optimal_portfolios['max_calmar'].copy()
                )
                self.monthly_weights_history['high_return_weights'].append(
                    self.optimal_portfolios['high_return'].copy()
                )
                
                print(f"ä¼˜åŒ–å®Œæˆï¼Œè®­ç»ƒæ•°æ®: {len(train_data)} ä¸ªäº¤æ˜“æ—¥")
                
                # è¾“å‡ºå„ç­–ç•¥çš„æƒé‡åˆ†é…
                print("\nğŸ” æœ¬æ¬¡è°ƒä»“æƒé‡åˆ†é…ï¼š")
                strategies = [
                    ('æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ', self.optimal_portfolios['max_sharpe']),
                    ('æœ€å¤§å¡ç›æ¯”ç‡ç»„åˆ', self.optimal_portfolios['max_calmar']),
                    ('æ§åˆ¶å›æ’¤é«˜æ”¶ç›Šç»„åˆ', self.optimal_portfolios['high_return'])
                ]
                
                for strategy_name, weights in strategies:
                    print(f"\nğŸ“Š {strategy_name}:")
                    for j, (etf_code, etf_name) in enumerate(self.etf_codes.items()):
                        if j < len(weights) and weights[j] > 0.001:  # åªæ˜¾ç¤ºæƒé‡å¤§äº0.1%çš„èµ„äº§
                            print(f"   {etf_name:15} ({etf_code}): {weights[j]:7.1%}")
                
                print("-" * 60)
                
            except Exception as e:
                print(f"ä¼˜åŒ–å¤±è´¥: {e}")
                # ä½¿ç”¨ç­‰æƒé‡ä½œä¸ºå¤‡é€‰
                num_assets = len(self.etf_codes)
                equal_weights = np.array([1/num_assets] * num_assets)
                
                self.monthly_weights_history['dates'].append(rebalance_date)
                self.monthly_weights_history['max_sharpe_weights'].append(equal_weights)
                self.monthly_weights_history['max_calmar_weights'].append(equal_weights)
                self.monthly_weights_history['high_return_weights'].append(equal_weights)
                print(f"ä½¿ç”¨ç­‰æƒé‡ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
                
                # è¾“å‡ºç­‰æƒé‡åˆ†é…
                print("\nğŸ” æœ¬æ¬¡è°ƒä»“æƒé‡åˆ†é…ï¼ˆç­‰æƒé‡å¤‡é€‰ï¼‰ï¼š")
                print(f"ğŸ“Š æ‰€æœ‰ç­–ç•¥å‡é‡‡ç”¨ç­‰æƒé‡:")
                for etf_code, etf_name in self.etf_codes.items():
                    print(f"   {etf_name:15} ({etf_code}): {1/num_assets:7.1%}")
                print("-" * 60)
            
            finally:
                self.data = original_data
        
        print(f"\næœ€ç»ˆè°ƒä»“ç»Ÿè®¡:")
        print(f"æ€»è°ƒä»“å°è¯•æ¬¡æ•°: {len(rebalance_dates)}")
        print(f"æˆåŠŸè°ƒä»“æ¬¡æ•°: {len(self.monthly_weights_history['dates'])}")
        print(f"è·³è¿‡æ¬¡æ•°: {len(rebalance_dates) - len(self.monthly_weights_history['dates'])}")
        
        # è®¡ç®—æœˆåº¦è°ƒä»“ç­–ç•¥çš„æ”¶ç›Šç‡
        self._calculate_monthly_returns(start_dt, end_dt)
        
        # åˆ†ææœˆåº¦è°ƒä»“ç»“æœ
        self._analyze_monthly_results()
        
        return self.monthly_backtest_results
    
    def _calculate_monthly_returns(self, start_date, end_date):
        """
        è®¡ç®—æœˆåº¦è°ƒä»“ç­–ç•¥çš„æ”¶ç›Šç‡
        """
        # è·å–å›æµ‹æœŸé—´çš„æ•°æ®
        backtest_data = self.data[
            (self.data.index >= start_date) & 
            (self.data.index <= end_date)
        ].copy()
        
        returns = backtest_data.pct_change().dropna()
        
        # åˆå§‹åŒ–æ—¥åº¦æ•°æ®å­˜å‚¨
        portfolio_daily_returns = {
            'max_sharpe': pd.Series(index=returns.index, dtype=float),
            'max_calmar': pd.Series(index=returns.index, dtype=float),
            'high_return': pd.Series(index=returns.index, dtype=float)
        }
        
        portfolio_cumulative_returns = {
            'max_sharpe': pd.Series(index=returns.index, dtype=float),
            'max_calmar': pd.Series(index=returns.index, dtype=float),
            'high_return': pd.Series(index=returns.index, dtype=float)
        }
        
        # åˆå§‹åŒ–ç»„åˆä»·å€¼
        portfolio_values = {
            'max_sharpe': 1.0,
            'max_calmar': 1.0,
            'high_return': 1.0
        }
        
        current_weights = {
            'max_sharpe': None,
            'max_calmar': None,
            'high_return': None
        }
        
        rebalance_dates = self.monthly_weights_history['dates']
        weight_index = 0
        
        # ç¡®ä¿æƒé‡åˆ—è¡¨é•¿åº¦ä¸€è‡´
        min_weights_length = min(
            len(self.monthly_weights_history['max_sharpe_weights']),
            len(self.monthly_weights_history['max_calmar_weights']),
            len(self.monthly_weights_history['high_return_weights']),
            len(rebalance_dates)
        )
        
        for date in returns.index:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒä»“
            if (weight_index < min_weights_length and 
                weight_index < len(rebalance_dates) and
                date >= rebalance_dates[weight_index]):
                
                current_weights['max_sharpe'] = self.monthly_weights_history['max_sharpe_weights'][weight_index]
                current_weights['max_calmar'] = self.monthly_weights_history['max_calmar_weights'][weight_index]
                current_weights['high_return'] = self.monthly_weights_history['high_return_weights'][weight_index]
                weight_index += 1
            
            # è®¡ç®—å½“æ—¥æ”¶ç›Šç‡
            if current_weights['max_sharpe'] is not None:
                daily_returns = returns.loc[date]
                
                for strategy in ['max_sharpe', 'max_calmar', 'high_return']:
                    weights = current_weights[strategy]
                    portfolio_return = np.sum(daily_returns * weights)
                    portfolio_values[strategy] *= (1 + portfolio_return)
                    portfolio_daily_returns[strategy].loc[date] = portfolio_return
                    portfolio_cumulative_returns[strategy].loc[date] = portfolio_values[strategy]
        
        # ä¿å­˜æ—¥åº¦å’Œç´¯è®¡æ”¶ç›Šæ•°æ®
        self.monthly_portfolio_returns = portfolio_cumulative_returns
        self.daily_portfolio_returns = portfolio_daily_returns
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        self.monthly_backtest_results = {}
        
        for strategy in ['max_sharpe', 'max_calmar', 'high_return']:
            cum_returns = portfolio_cumulative_returns[strategy].dropna()
            daily_rets = portfolio_daily_returns[strategy].dropna()
            
            if len(cum_returns) > 0:
                total_return = cum_returns.iloc[-1] - 1
                annual_return = daily_rets.mean() * 252
                annual_volatility = daily_rets.std() * np.sqrt(252)
                sharpe_ratio = annual_return / annual_volatility if annual_volatility > 0 else 0
                
                # è®¡ç®—æœ€å¤§å›æ’¤
                peak = cum_returns.expanding().max()
                drawdown = (cum_returns - peak) / peak
                max_drawdown = abs(drawdown.min())
                
                calmar_ratio = annual_return / max_drawdown if max_drawdown > 0 else 0
                win_rate = (daily_rets > 0).mean()
                
                self.monthly_backtest_results[strategy] = {
                    'cumulative_returns': cum_returns,
                    'daily_returns': daily_rets,
                    'total_return': total_return,
                    'annual_return': annual_return,
                    'annual_volatility': annual_volatility,
                    'sharpe_ratio': sharpe_ratio,
                    'max_drawdown': max_drawdown,
                    'calmar_ratio': calmar_ratio,
                    'win_rate': win_rate
                }
    
    def _analyze_monthly_results(self):
        """
        åˆ†ææœˆåº¦è°ƒä»“ç»“æœ
        """
        print("\n" + "="*80)
        print("æœˆåº¦è°ƒä»“ç­–ç•¥å›æµ‹ç»“æœ")
        print("="*80)
        
        strategy_names = {
            'max_sharpe': 'æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ',
            'max_calmar': 'æœ€å¤§å¡ç›æ¯”ç‡ç»„åˆ', 
            'high_return': 'æ§åˆ¶å›æ’¤é«˜æ”¶ç›Šç»„åˆ'
        }
        
        for strategy, name in strategy_names.items():
            if strategy in self.monthly_backtest_results:
                result = self.monthly_backtest_results[strategy]
                
                print(f"\nğŸ“Œ {name} - æœˆåº¦è°ƒä»“è¡¨ç°")
                print("-" * 50)
                print(f"æ€»æ”¶ç›Šç‡: {result['total_return']:.2%}")
                print(f"å¹´åŒ–æ”¶ç›Šç‡: {result['annual_return']:.2%}")
                print(f"å¹´åŒ–æ³¢åŠ¨ç‡: {result['annual_volatility']:.2%}")
                print(f"å¤æ™®æ¯”ç‡: {result['sharpe_ratio']:.3f}")
                print(f"æœ€å¤§å›æ’¤: {result['max_drawdown']:.2%}")
                print(f"å¡ç›æ¯”ç‡: {result['calmar_ratio']:.3f}")
                print(f"èƒœç‡: {result['win_rate']:.1%}")
                
        # è¾“å‡ºæœ€æ–°è°ƒä»“ä¿¡æ¯
        self._print_latest_weights()
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"\nè°ƒè¯•ä¿¡æ¯:")
        print(f"è°ƒä»“æ—¥æœŸæ•°é‡: {len(self.monthly_weights_history['dates'])}")
        print(f"æœ€å¤§å¤æ™®æƒé‡æ•°é‡: {len(self.monthly_weights_history['max_sharpe_weights'])}")
        print(f"æœ€å¤§å¡ç›æƒé‡æ•°é‡: {len(self.monthly_weights_history['max_calmar_weights'])}")
        print(f"é«˜æ”¶ç›Šæƒé‡æ•°é‡: {len(self.monthly_weights_history['high_return_weights'])}")
    
    def _print_latest_weights(self):
        """
        è¾“å‡ºæœ€æ–°ä¸€æœŸçš„æƒé‡åˆ†é…
        """
        if (hasattr(self, 'monthly_weights_history') and 
            len(self.monthly_weights_history['dates']) > 0):
            
            print(f"\n" + "="*80)
            print("ğŸ“‹ æœ€æ–°ä¸€æœŸæƒé‡åˆ†é…è¯¦æƒ…")
            print("="*80)
            
            latest_date = self.monthly_weights_history['dates'][-1]
            print(f"è°ƒä»“æ—¥æœŸ: {latest_date.strftime('%Y-%m-%d')}")
            
            # ç­–ç•¥åç§°æ˜ å°„
            strategies = {
                'max_sharpe': ('æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ', self.monthly_weights_history['max_sharpe_weights'][-1]),
                'max_calmar': ('æœ€å¤§å¡ç›æ¯”ç‡ç»„åˆ', self.monthly_weights_history['max_calmar_weights'][-1]),
                'high_return': ('æ§åˆ¶å›æ’¤é«˜æ”¶ç›Šç»„åˆ', self.monthly_weights_history['high_return_weights'][-1])
            }
            
            for strategy_key, (strategy_name, weights) in strategies.items():
                print(f"\nğŸ“Š {strategy_name}:")
                print("-" * 50)
                
                # æŒ‰æƒé‡å¤§å°æ’åºè¾“å‡º
                weight_pairs = []
                for j, (etf_code, etf_name) in enumerate(self.etf_codes.items()):
                    if j < len(weights):
                        weight_pairs.append((weights[j], etf_name, etf_code))
                
                # æŒ‰æƒé‡ä»å¤§åˆ°å°æ’åº
                weight_pairs.sort(reverse=True)
                
                for weight, etf_name, etf_code in weight_pairs:
                    if weight > 0.001:  # åªæ˜¾ç¤ºæƒé‡å¤§äº0.1%çš„èµ„äº§
                        print(f"   {etf_name:15} ({etf_code}): {weight:7.1%}")
            
            print("="*80)
    
    def plot_monthly_backtest_results(self, save_path=None):
        """
        ç»˜åˆ¶æœˆåº¦è°ƒä»“å›æµ‹ç»“æœå›¾è¡¨
        """
        if not hasattr(self, 'monthly_backtest_results'):
            raise ValueError("è¯·å…ˆè¿›è¡Œæœˆåº¦è°ƒä»“å›æµ‹")
        
        fig = plt.figure(figsize=(20, 16))
        
        # åˆ›å»ºç½‘æ ¼å¸ƒå±€
        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
        
        strategy_names = {
            'max_sharpe': 'æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ',
            'max_calmar': 'æœ€å¤§å¡ç›æ¯”ç‡ç»„åˆ', 
            'high_return': 'æ§åˆ¶å›æ’¤é«˜æ”¶ç›Šç»„åˆ'
        }
        colors = ['red', 'blue', 'green']
        
        # 1. ç´¯è®¡æ”¶ç›Šç‡æ›²çº¿å¯¹æ¯”
        ax1 = fig.add_subplot(gs[0, :])
        for i, (strategy, name) in enumerate(strategy_names.items()):
            if strategy in self.monthly_backtest_results:
                cum_returns = self.monthly_backtest_results[strategy]['cumulative_returns']
                ax1.plot(cum_returns.index, cum_returns, label=name, 
                        color=colors[i], linewidth=2)
        
        ax1.set_title('æœˆåº¦è°ƒä»“ç­–ç•¥ç´¯è®¡æ”¶ç›Šç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax1.set_ylabel('ç´¯è®¡æ”¶ç›Šç‡')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. æƒé‡å˜åŒ–çƒ­åŠ›å›¾ï¼ˆä»¥æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆä¸ºä¾‹ï¼‰
        if len(self.monthly_weights_history['max_sharpe_weights']) > 0:
            ax2 = fig.add_subplot(gs[1, 0])
            weights_df = pd.DataFrame(
                self.monthly_weights_history['max_sharpe_weights'],
                index=[d.strftime('%Y-%m') for d in self.monthly_weights_history['dates']],
                columns=list(self.etf_codes.values())
            )
            
            im = ax2.imshow(weights_df.T, cmap='RdYlBu', aspect='auto')
            ax2.set_title('æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆæƒé‡å˜åŒ–')
            ax2.set_ylabel('èµ„äº§')
            ax2.set_xlabel('è°ƒä»“æ—¶é—´')
            ax2.set_yticks(range(len(self.etf_codes)))
            ax2.set_yticklabels(list(self.etf_codes.values()), fontsize=8)
            ax2.set_xticks(range(0, len(weights_df), max(1, len(weights_df)//6)))
            ax2.set_xticklabels([weights_df.index[i] for i in range(0, len(weights_df), max(1, len(weights_df)//6))], 
                              rotation=45, fontsize=8)
            plt.colorbar(im, ax=ax2, shrink=0.8)
        
        # 3. å¹´åŒ–æ”¶ç›Šç‡å¯¹æ¯”
        ax3 = fig.add_subplot(gs[1, 1])
        annual_returns = [self.monthly_backtest_results[s]['annual_return'] 
                         for s in strategy_names.keys() if s in self.monthly_backtest_results]
        strategy_labels = [strategy_names[s] for s in strategy_names.keys() 
                          if s in self.monthly_backtest_results]
        
        bars = ax3.bar(range(len(annual_returns)), annual_returns, 
                      color=colors[:len(annual_returns)], alpha=0.7)
        ax3.set_title('å¹´åŒ–æ”¶ç›Šç‡å¯¹æ¯”')
        ax3.set_ylabel('å¹´åŒ–æ”¶ç›Šç‡')
        ax3.set_xticks(range(len(strategy_labels)))
        ax3.set_xticklabels([s.replace('ç»„åˆ', '') for s in strategy_labels], rotation=45)
        ax3.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, annual_returns):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{value:.1%}', ha='center', va='bottom')
        
        # 4. å¤æ™®æ¯”ç‡å¯¹æ¯”
        ax4 = fig.add_subplot(gs[1, 2])
        sharpe_ratios = [self.monthly_backtest_results[s]['sharpe_ratio'] 
                        for s in strategy_names.keys() if s in self.monthly_backtest_results]
        
        bars = ax4.bar(range(len(sharpe_ratios)), sharpe_ratios, 
                      color=colors[:len(sharpe_ratios)], alpha=0.7)
        ax4.set_title('å¤æ™®æ¯”ç‡å¯¹æ¯”')
        ax4.set_ylabel('å¤æ™®æ¯”ç‡')
        ax4.set_xticks(range(len(strategy_labels)))
        ax4.set_xticklabels([s.replace('ç»„åˆ', '') for s in strategy_labels], rotation=45)
        ax4.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, sharpe_ratios):
            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, 
                    f'{value:.2f}', ha='center', va='bottom')
        
        # 5. æœ€å¤§å›æ’¤å¯¹æ¯”
        ax5 = fig.add_subplot(gs[2, 0])
        max_drawdowns = [self.monthly_backtest_results[s]['max_drawdown'] 
                        for s in strategy_names.keys() if s in self.monthly_backtest_results]
        
        bars = ax5.bar(range(len(max_drawdowns)), max_drawdowns, 
                      color=colors[:len(max_drawdowns)], alpha=0.7)
        ax5.set_title('æœ€å¤§å›æ’¤å¯¹æ¯”')
        ax5.set_ylabel('æœ€å¤§å›æ’¤')
        ax5.set_xticks(range(len(strategy_labels)))
        ax5.set_xticklabels([s.replace('ç»„åˆ', '') for s in strategy_labels], rotation=45)
        ax5.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, max_drawdowns):
            ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, 
                    f'{value:.1%}', ha='center', va='bottom')
        
        # 6. æ»šåŠ¨å›æ’¤æ›²çº¿
        ax6 = fig.add_subplot(gs[2, 1:])
        for i, (strategy, name) in enumerate(strategy_names.items()):
            if strategy in self.monthly_backtest_results:
                cum_returns = self.monthly_backtest_results[strategy]['cumulative_returns']
                peak = cum_returns.expanding().max()
                drawdown = (cum_returns - peak) / peak
                ax6.fill_between(drawdown.index, drawdown, 0, alpha=0.3, color=colors[i])
                ax6.plot(drawdown.index, drawdown, label=name, color=colors[i], linewidth=1)
        
        ax6.set_title('æ»šåŠ¨å›æ’¤æ›²çº¿')
        ax6.set_ylabel('å›æ’¤')
        ax6.legend()
        ax6.grid(True, alpha=0.3)
        
        plt.suptitle('æœˆåº¦åŠ¨æ€è°ƒä»“ç­–ç•¥åˆ†ææŠ¥å‘Š', fontsize=16, fontweight='bold')
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"æœˆåº¦è°ƒä»“å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def run_monthly_analysis(self, start_date='20210101', end_date=None, 
                           lookback_months=12, rebalance_days=[1, 15], save_results=True):
        """
        è¿è¡Œå®Œæ•´çš„æœˆåº¦è°ƒä»“åˆ†æ
        
        Parameters:
        - start_date: å›æµ‹å¼€å§‹æ—¥æœŸ
        - end_date: å›æµ‹ç»“æŸæ—¥æœŸ
        - lookback_months: ä¼˜åŒ–æ—¶ä½¿ç”¨çš„å†å²æ•°æ®é•¿åº¦(æœˆ)
        - rebalance_days: æ¯æœˆè°ƒä»“æ—¥æœŸåˆ—è¡¨ï¼Œé»˜è®¤[1, 15]è¡¨ç¤ºæ¯æœˆ1æ—¥å’Œ15æ—¥è°ƒä»“
        - save_results: æ˜¯å¦ä¿å­˜ç»“æœ
        """
        # æ‰§è¡Œæœˆåº¦è°ƒä»“å›æµ‹
        monthly_results = self.monthly_rebalancing_backtest(
            start_date=start_date, 
            end_date=end_date,
            lookback_months=lookback_months,
            rebalance_days=rebalance_days
        )
        
        # ç»˜åˆ¶åˆ†æå›¾è¡¨
        if save_results:
            save_path = 'monthly_rebalancing_analysis.png'
            self.plot_monthly_backtest_results(save_path=save_path)
        else:
            self.plot_monthly_backtest_results()
        
        # ä¿å­˜è¯¦ç»†æ•°æ®
        if save_results:
            self.save_monthly_results(start_date, end_date, lookback_months, rebalance_days)
        
        return monthly_results
    
    def save_monthly_results(self, start_date, end_date, lookback_months, rebalance_days=[1, 15]):
        """
        ä¿å­˜æœˆåº¦è°ƒä»“åˆ†æçš„è¯¦ç»†ç»“æœ
        """
        print("\næ­£åœ¨ä¿å­˜åˆ†æç»“æœ...")
        
        # 1. ä¿å­˜ç­–ç•¥è¡¨ç°æ±‡æ€»
        strategy_names = {
            'max_sharpe': 'æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ',
            'max_calmar': 'æœ€å¤§å¡ç›æ¯”ç‡ç»„åˆ', 
            'high_return': 'æ§åˆ¶å›æ’¤é«˜æ”¶ç›Šç»„åˆ'
        }
        
        summary_data = []
        for strategy, name in strategy_names.items():
            if strategy in self.monthly_backtest_results:
                result = self.monthly_backtest_results[strategy]
                summary_data.append({
                    'ç­–ç•¥åç§°': name,
                    'ç­–ç•¥ä»£ç ': strategy,
                    'æ€»æ”¶ç›Šç‡': f"{result['total_return']:.4f}",
                    'å¹´åŒ–æ”¶ç›Šç‡': f"{result['annual_return']:.4f}",
                    'å¹´åŒ–æ³¢åŠ¨ç‡': f"{result['annual_volatility']:.4f}",
                    'å¤æ™®æ¯”ç‡': f"{result['sharpe_ratio']:.4f}",
                    'æœ€å¤§å›æ’¤': f"{result['max_drawdown']:.4f}",
                    'å¡ç›æ¯”ç‡': f"{result['calmar_ratio']:.4f}",
                    'èƒœç‡': f"{result['win_rate']:.4f}",
                    'å›æµ‹å¼€å§‹æ—¥æœŸ': start_date,
                    'å›æµ‹ç»“æŸæ—¥æœŸ': end_date or datetime.now().strftime('%Y%m%d'),
                    'å†å²æ•°æ®çª—å£_æœˆ': lookback_months,
                    'è°ƒä»“æ—¥æœŸ': str(rebalance_days)
                })
        
        summary_df = pd.DataFrame(summary_data)
        summary_df.to_csv('æœˆåº¦è°ƒä»“ç­–ç•¥è¡¨ç°æ±‡æ€».csv', index=False, encoding='utf-8-sig')
        print("âœ… ç­–ç•¥è¡¨ç°æ±‡æ€»å·²ä¿å­˜: æœˆåº¦è°ƒä»“ç­–ç•¥è¡¨ç°æ±‡æ€».csv")
        
        # 2. ä¿å­˜å†å²æŒä»“æ˜ç»†
        if hasattr(self, 'monthly_weights_history') and len(self.monthly_weights_history['dates']) > 0:
            holdings_data = []
            
            # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
            dates = self.monthly_weights_history['dates']
            min_length = min(
                len(dates),
                len(self.monthly_weights_history['max_sharpe_weights']),
                len(self.monthly_weights_history['max_calmar_weights']),
                len(self.monthly_weights_history['high_return_weights'])
            )
            
            for i in range(min_length):
                date = dates[i]
                # ä¸ºæ¯ä¸ªç­–ç•¥å’Œæ¯ä¸ªèµ„äº§åˆ›å»ºè®°å½•
                for strategy_key, strategy_name in strategy_names.items():
                    weights = None
                    if strategy_key == 'max_sharpe':
                        weights = self.monthly_weights_history['max_sharpe_weights'][i]
                    elif strategy_key == 'max_calmar':
                        weights = self.monthly_weights_history['max_calmar_weights'][i]
                    elif strategy_key == 'high_return':
                        weights = self.monthly_weights_history['high_return_weights'][i]
                    
                    if weights is not None:
                        for j, (etf_code, etf_name) in enumerate(self.etf_codes.items()):
                            if j < len(weights):
                                holdings_data.append({
                                    'è°ƒä»“æ—¥æœŸ': date.strftime('%Y-%m-%d'),
                                    'ç­–ç•¥åç§°': strategy_name,
                                    'ç­–ç•¥ä»£ç ': strategy_key,
                                    'ETFä»£ç ': etf_code,
                                    'ETFåç§°': etf_name,
                                    'æƒé‡': f"{weights[j]:.6f}",
                                    'æƒé‡ç™¾åˆ†æ¯”': f"{weights[j]*100:.2f}%"
                                })
            
            if holdings_data:
                holdings_df = pd.DataFrame(holdings_data)
                holdings_df.to_csv('æœˆåº¦è°ƒä»“å†å²æŒä»“æ˜ç»†.csv', index=False, encoding='utf-8-sig')
                print("âœ… å†å²æŒä»“æ˜ç»†å·²ä¿å­˜: æœˆåº¦è°ƒä»“å†å²æŒä»“æ˜ç»†.csv")
            else:
                print("âš ï¸ æ²¡æœ‰æŒä»“æ•°æ®å¯ä¿å­˜")
        
        # 3. ä¿å­˜æ¯æ—¥æ”¶ç›Šæ˜ç»†
        if hasattr(self, 'monthly_backtest_results') and self.monthly_backtest_results:
            daily_returns_data = []
            
            for strategy, name in strategy_names.items():
                if strategy in self.monthly_backtest_results:
                    cum_returns = self.monthly_backtest_results[strategy]['cumulative_returns']
                    daily_returns = self.monthly_backtest_results[strategy]['daily_returns']
                    
                    for date in cum_returns.index:
                        daily_returns_data.append({
                            'æ—¥æœŸ': date.strftime('%Y-%m-%d'),
                            'ç­–ç•¥åç§°': name,
                            'ç­–ç•¥ä»£ç ': strategy,
                            'æ—¥åº¦æ”¶ç›Šç‡': f"{daily_returns.loc[date]:.6f}" if date in daily_returns.index else "0.000000",
                            'æ—¥åº¦æ”¶ç›Šç‡ç™¾åˆ†æ¯”': f"{daily_returns.loc[date]*100:.4f}%" if date in daily_returns.index else "0.0000%",
                            'ç´¯è®¡å‡€å€¼': f"{cum_returns.loc[date]:.6f}",
                            'ç´¯è®¡æ”¶ç›Šç‡': f"{(cum_returns.loc[date]-1)*100:.2f}%"
                        })
            
            if daily_returns_data:
                daily_returns_df = pd.DataFrame(daily_returns_data)
                daily_returns_df.to_csv('æœˆåº¦è°ƒä»“æ¯æ—¥æ”¶ç›Šæ˜ç»†.csv', index=False, encoding='utf-8-sig')
                print("âœ… æ¯æ—¥æ”¶ç›Šæ˜ç»†å·²ä¿å­˜: æœˆåº¦è°ƒä»“æ¯æ—¥æ”¶ç›Šæ˜ç»†.csv")
            else:
                print("âš ï¸ æ²¡æœ‰æ”¶ç›Šæ•°æ®å¯ä¿å­˜")
        
        # 4. ä¿å­˜æƒé‡å˜åŒ–é€è§†è¡¨ï¼ˆä¾¿äºåˆ†æï¼‰
        if hasattr(self, 'monthly_weights_history') and len(self.monthly_weights_history['dates']) > 0:
            dates = self.monthly_weights_history['dates']
            min_length = min(
                len(dates),
                len(self.monthly_weights_history['max_sharpe_weights']),
                len(self.monthly_weights_history['max_calmar_weights']),
                len(self.monthly_weights_history['high_return_weights'])
            )
            
            # ä¸ºæ¯ä¸ªç­–ç•¥åˆ›å»ºæƒé‡å˜åŒ–è¡¨
            for strategy_key, strategy_name in strategy_names.items():
                weights_list = None
                if strategy_key == 'max_sharpe':
                    weights_list = self.monthly_weights_history['max_sharpe_weights']
                elif strategy_key == 'max_calmar':
                    weights_list = self.monthly_weights_history['max_calmar_weights']
                elif strategy_key == 'high_return':
                    weights_list = self.monthly_weights_history['high_return_weights']
                
                if weights_list and len(weights_list) > 0:
                    weights_pivot_data = []
                    for i in range(min(min_length, len(weights_list))):
                        date = dates[i]
                        row = {'è°ƒä»“æ—¥æœŸ': date.strftime('%Y-%m-%d')}
                        weights = weights_list[i]
                        for j, (etf_code, etf_name) in enumerate(self.etf_codes.items()):
                            if j < len(weights):
                                row[f"{etf_name}({etf_code})"] = f"{weights[j]:.4f}"
                        weights_pivot_data.append(row)
                    
                    if weights_pivot_data:
                        weights_pivot_df = pd.DataFrame(weights_pivot_data)
                        filename = f'{strategy_name}_æƒé‡å˜åŒ–è¡¨.csv'
                        weights_pivot_df.to_csv(filename, index=False, encoding='utf-8-sig')
                        print(f"âœ… {strategy_name}æƒé‡å˜åŒ–è¡¨å·²ä¿å­˜: {filename}")
                    else:
                        print(f"âš ï¸ {strategy_name}æ²¡æœ‰æƒé‡æ•°æ®å¯ä¿å­˜")
        
        # 5. ä¿å­˜åˆ†æå‚æ•°å’Œå…ƒæ•°æ®
        metadata = {
            'åˆ†æå‚æ•°': [
                f"å›æµ‹å¼€å§‹æ—¥æœŸ: {start_date}",
                f"å›æµ‹ç»“æŸæ—¥æœŸ: {end_date or datetime.now().strftime('%Y%m%d')}",
                f"å†å²æ•°æ®çª—å£: {lookback_months} ä¸ªæœˆ",
                f"è°ƒä»“é¢‘ç‡: æ¯æœˆ{rebalance_days}æ—¥",
                f"è°ƒä»“æ¬¡æ•°: æ¯æœˆ{len(rebalance_days)}æ¬¡",
                f"ETFæ•°é‡: {len(self.etf_codes)}",
                f"ç­–ç•¥æ•°é‡: {len(strategy_names)}",
                f"åˆ†æç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            ]
        }
        
        metadata_df = pd.DataFrame(metadata)
        metadata_df.to_csv('åˆ†æå‚æ•°å’Œå…ƒæ•°æ®.csv', index=False, encoding='utf-8-sig', header=False)
        print("âœ… åˆ†æå‚æ•°å’Œå…ƒæ•°æ®å·²ä¿å­˜: åˆ†æå‚æ•°å’Œå…ƒæ•°æ®.csv")
        
        print(f"\nğŸ‰ æ‰€æœ‰åˆ†æç»“æœå·²ä¿å­˜å®Œæˆï¼")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨:")
        print("   1. æœˆåº¦è°ƒä»“ç­–ç•¥è¡¨ç°æ±‡æ€».csv - ç­–ç•¥æ•´ä½“è¡¨ç°")
        print("   2. æœˆåº¦è°ƒä»“å†å²æŒä»“æ˜ç»†.csv - æ¯æ¬¡è°ƒä»“çš„è¯¦ç»†æŒä»“")
        print("   3. æœˆåº¦è°ƒä»“æ¯æ—¥æ”¶ç›Šæ˜ç»†.csv - æ¯æ—¥æ”¶ç›Šç‡å’Œå‡€å€¼å˜åŒ–")
        print("   4. [ç­–ç•¥åç§°]_æƒé‡å˜åŒ–è¡¨.csv - å„ç­–ç•¥æƒé‡å˜åŒ–é€è§†è¡¨")
        print("   5. åˆ†æå‚æ•°å’Œå…ƒæ•°æ®.csv - åˆ†æé…ç½®ä¿¡æ¯")
        print("   6. monthly_rebalancing_analysis.png - å¯è§†åŒ–åˆ†æå›¾è¡¨")

def main():
    """
    ä¸»å‡½æ•°
    """
    # åˆ›å»ºæœ‰æ•ˆå‰æ²¿åˆ†æå™¨
    ef_analyzer = EfficientFrontierETF()
    
    # è¿è¡Œæ ·æœ¬å†…å¤–åˆ†æ
    try:
        # æ–¹æ³•1: è¿è¡Œæ ·æœ¬å†…å¤–åˆ†æ (æ¨è)
        # results = ef_analyzer.run_in_out_sample_analysis(
        #     in_sample_start='20210101', 
        #     in_sample_end='20230630',
        #     out_sample_start='20240101'
        # )
        
        # print("\n" + "="*80)
        # print("å¼€å§‹æœˆåº¦åŠ¨æ€è°ƒä»“åˆ†æ...")
        # print("="*80)
        
        # æ–¹æ³•3: è¿è¡Œæœˆåº¦åŠ¨æ€è°ƒä»“å›æµ‹ (æ–°å¢) - æ¯æœˆæœˆåˆå’Œæœˆä¸­è°ƒä»“
        monthly_results = ef_analyzer.run_monthly_analysis(
            start_date='20200101',      # è°ƒä»“å›æµ‹å¼€å§‹æ—¥æœŸ
            lookback_months=12,         # ä½¿ç”¨12ä¸ªæœˆå†å²æ•°æ®è¿›è¡Œä¼˜åŒ–
            rebalance_days=[1, 15],     # æ¯æœˆ1æ—¥å’Œ15æ—¥è°ƒä»“
            save_results=True
        )
        
        print("\næŠ•èµ„å»ºè®®æ€»ç»“:")
        print("="*80)
        print("ğŸ“Œ ç»„åˆä¸€ï¼šç¨³ä¸­æ±‚èƒœï¼ˆæœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆï¼‰")
        print("   ç‰¹ç‚¹ï¼šé£é™©è°ƒæ•´åæ”¶ç›Šæœ€ä¼˜ï¼Œé€‚åˆç¨³å¥å‹æŠ•èµ„è€…")
        print("   é€‚ç”¨åœºæ™¯ï¼šè¿½æ±‚é•¿æœŸç¨³å®šæ”¶ç›Šï¼Œä¸å¸Œæœ›æ‰¿å—è¿‡å¤§æ³¢åŠ¨")
        
        print("\nğŸ“Œ ç»„åˆäºŒï¼šæ§åˆ¶å›æ’¤ï¼ˆæœ€å¤§å¡ç›æ¯”ç‡ç»„åˆï¼‰") 
        print("   ç‰¹ç‚¹ï¼šåœ¨æ§åˆ¶å›æ’¤çš„å‰æä¸‹è·å¾—è¾ƒå¥½æ”¶ç›Š")
        print("   é€‚ç”¨åœºæ™¯ï¼šæ³¨é‡èµ„äº§ä¿å€¼ï¼Œèƒ½æ¥å—é€‚ä¸­æ”¶ç›Š")
        
        print("\nğŸ“Œ ç»„åˆä¸‰ï¼šå°å¿ƒæ¿€è¿›ï¼ˆæ§åˆ¶å›æ’¤çš„é«˜æ”¶ç›Šç»„åˆï¼‰")
        print("   ç‰¹ç‚¹ï¼šåœ¨10%å›æ’¤é™åˆ¶ä¸‹è¿½æ±‚æ›´é«˜æ”¶ç›Š")
        print("   é€‚ç”¨åœºæ™¯ï¼šé£é™©æ‰¿å—èƒ½åŠ›è¾ƒå¼ºï¼Œè¿½æ±‚è¾ƒé«˜æ”¶ç›Š")
        
        print("\næ³¨æ„ï¼š")
        print("- æ ·æœ¬å†…å¤–è¡¨ç°å­˜åœ¨å·®å¼‚æ˜¯æ­£å¸¸ç°è±¡")
        print("- å»ºè®®å…³æ³¨æ ·æœ¬å¤–çš„å¤æ™®æ¯”ç‡å’Œæœ€å¤§å›æ’¤æ§åˆ¶")
        print("- å¯æ ¹æ®å®é™…é£é™©åå¥½é€‰æ‹©åˆé€‚çš„æŠ•èµ„ç»„åˆ")
        print("- æ¯æœˆæœˆåˆå’Œæœˆä¸­è°ƒä»“ç­–ç•¥å¯ä»¥æ›´å¥½åœ°é€‚åº”å¸‚åœºå˜åŒ–")
        print("- å¢åŠ è°ƒä»“é¢‘ç‡æœ‰åŠ©äºåŠæ—¶è°ƒæ•´æŠ•èµ„ç»„åˆï¼Œä½†å¯èƒ½å¢åŠ äº¤æ˜“æˆæœ¬")
        
        # æ–¹æ³•2: ä¹Ÿå¯ä»¥è¿è¡Œä¼ ç»Ÿçš„å…¨æ ·æœ¬åˆ†æ
        # results = ef_analyzer.run_complete_analysis(start_date='20200101')
        
    except Exception as e:
        print(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæ•°æ®è·å–æƒ…å†µ")

if __name__ == "__main__":
    main()

